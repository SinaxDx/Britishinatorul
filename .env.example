# Copy this file to .env and fill in the values
DISCORD_TOKEN=
DISCORD_CLIENT_ID=
# Optional: use a Guild ID for faster slash-command deploys during development
DISCORD_GUILD_ID=

# Local AI integration (OpenAI-compatible server: Ollama / LM Studio)
OPENAI_BASE_URL=http://localhost:11434/v1
OPENAI_API_KEY=ollama

# Note: Model, System Prompt, and Performance settings are now configured in 'botConfig.json'
